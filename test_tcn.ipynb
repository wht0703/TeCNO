{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2025-03-14T13:42:05.786550Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from models.mstcn import MultiStageModel\n",
    "\n",
    "ckpt_path = 'logs/250314-131556_TeCNO_Cholec80_mstcn_MultiStageModel/checkpoints/epoch=15-val_acc=0.27.ckpt'\n",
    "\n",
    "\n",
    "class HParams:\n",
    "    def __init__(self, mstcn_stages, mstcn_layers, mstcn_f_maps, mstcn_f_dim, out_features, mstcn_causal_conv):\n",
    "        self.mstcn_stages = mstcn_stages\n",
    "        self.mstcn_layers = mstcn_layers\n",
    "        self.mstcn_f_maps = mstcn_f_maps\n",
    "        self.mstcn_f_dim = mstcn_f_dim\n",
    "        self.out_features = out_features\n",
    "        self.mstcn_causal_conv = mstcn_causal_conv\n",
    "\n",
    "\n",
    "def load_video(path):\n",
    "    unpickled_x = pd.read_pickle(path)\n",
    "    stem = np.asarray(unpickled_x[0],\n",
    "                      dtype=np.float32)[::25]\n",
    "    y_hat = np.asarray(unpickled_x[1],\n",
    "                       dtype=np.float32)[::25]\n",
    "    y = np.asarray(unpickled_x[2])[::25]\n",
    "    return stem, y_hat, y\n",
    "\n",
    "video_index = 55\n",
    "video_path = f'logs/250119-122819_FeatureExtraction_Cholec80FeatureExtract_cnn_OneHeadResNet50Model/cholec80_pickle_export/1.0fps/video_{video_index}_25.0fps.pkl'\n",
    "\n",
    "def main():\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = MultiStageModel(HParams(\n",
    "        mstcn_stages=2,\n",
    "        mstcn_layers=8,\n",
    "        mstcn_f_maps=32,\n",
    "        mstcn_f_dim=2048,\n",
    "        out_features=13,\n",
    "        mstcn_causal_conv=True\n",
    "    ))\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device, weights_only=True)\n",
    "    new_state_dict = {}\n",
    "    for key, values in checkpoint['state_dict'].items():\n",
    "        if key.startswith('model.'):\n",
    "            new_key = key.replace('model.', '')\n",
    "        else:\n",
    "            new_key = key\n",
    "        new_state_dict[new_key] = values\n",
    "    for unwanted_key in [\"ce_loss.weight\"]:\n",
    "        if unwanted_key in new_state_dict:\n",
    "            del new_state_dict[unwanted_key]\n",
    "    model.load_state_dict(new_state_dict, strict=True)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    stem, _, y = load_video(video_path)\n",
    "    stem = torch.tensor(stem).to(device)\n",
    "    with torch.no_grad():\n",
    "        steam = stem.transpose(2, 1)\n",
    "        out_stem = model(stem)\n",
    "    phases = torch.softmax(out_stem, dim=2)\n",
    "    print(y)\n",
    "    print(phases)\n",
    "    \n",
    "main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "num_stages_classification: 2, num_layers: 8, num_f_maps: 32, dim: 2048\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 66\u001B[0m\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;28mprint\u001B[39m(y)\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;28mprint\u001B[39m(phases)\n\u001B[0;32m---> 66\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[2], line 57\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     55\u001B[0m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     56\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m---> 57\u001B[0m stem, _, y \u001B[38;5;241m=\u001B[39m \u001B[43mload_video\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvideo_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m stem \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(stem)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "Cell \u001B[0;32mIn[2], line 26\u001B[0m, in \u001B[0;36mload_video\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m     22\u001B[0m stem \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(unpickled_x[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m     23\u001B[0m                   dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat32)[::\u001B[38;5;241m25\u001B[39m]\n\u001B[1;32m     24\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(unpickled_x[\u001B[38;5;241m1\u001B[39m],\n\u001B[1;32m     25\u001B[0m                    dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat32)[::\u001B[38;5;241m25\u001B[39m]\n\u001B[0;32m---> 26\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39masarray(unpickled_x[\u001B[38;5;241m2\u001B[39m])[::\u001B[38;5;241m25\u001B[39m]\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m stem, y_hat, y\n",
      "Cell \u001B[0;32mIn[2], line 26\u001B[0m, in \u001B[0;36mload_video\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m     22\u001B[0m stem \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(unpickled_x[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m     23\u001B[0m                   dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat32)[::\u001B[38;5;241m25\u001B[39m]\n\u001B[1;32m     24\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(unpickled_x[\u001B[38;5;241m1\u001B[39m],\n\u001B[1;32m     25\u001B[0m                    dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat32)[::\u001B[38;5;241m25\u001B[39m]\n\u001B[0;32m---> 26\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39masarray(unpickled_x[\u001B[38;5;241m2\u001B[39m])[::\u001B[38;5;241m25\u001B[39m]\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m stem, y_hat, y\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1103\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1061\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py:169\u001B[0m, in \u001B[0;36mstop\u001B[0;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[1;32m    167\u001B[0m     frame \u001B[38;5;241m=\u001B[39m suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[0;32m--> 169\u001B[0m         \u001B[43mmain_debugger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1207\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1204\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1206\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1207\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1222\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1219\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1221\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1222\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1224\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1226\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T13:41:33.078003Z",
     "start_time": "2025-03-14T13:09:25.956748Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "eb24bb7559682a5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
